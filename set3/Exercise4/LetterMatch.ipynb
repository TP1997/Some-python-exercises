{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing picture A22.png, skipping...\n",
      "Error processing picture B21.png, skipping...\n",
      "Error processing picture C21.png, skipping...\n",
      "Error processing picture D21.png, skipping...\n",
      "Error processing picture F20.png, skipping...\n",
      "Error processing picture G19.png, skipping...\n",
      "Error processing picture H21.png, skipping...\n",
      "Error processing picture I21.png, skipping...\n",
      "Error processing picture J21.png, skipping...\n",
      "Error processing picture K21.png, skipping...\n",
      "Error processing picture L21.png, skipping...\n",
      "Error processing picture M21.png, skipping...\n",
      "Error processing picture N21.png, skipping...\n",
      "Error processing picture O21.png, skipping...\n",
      "Error processing picture P21.png, skipping...\n",
      "Error processing picture Q21.png, skipping...\n",
      "Error processing picture R21.png, skipping...\n",
      "Error processing picture S21.png, skipping...\n",
      "Error processing picture T21.png, skipping...\n",
      "Error processing picture U21.png, skipping...\n",
      "Error processing picture V21.png, skipping...\n",
      "Error processing picture W21.png, skipping...\n",
      "Error processing picture X21.png, skipping...\n",
      "Error processing picture Y21.png, skipping...\n",
      "Error processing picture Z21.png, skipping...\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from skimage.restoration import denoise_tv_chambolle\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import threshold_otsu, gaussian\n",
    "from skimage.transform import resize\n",
    "from skimage.exposure import rescale_intensity\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "def removeSpace(img):\n",
    "    mask = img == 1\n",
    "    rows = np.flatnonzero((~mask).sum(axis=1))\n",
    "    cols = np.flatnonzero((~mask).sum(axis=0))\n",
    "    crop = img[rows.min():rows.max()+1, cols.min():cols.max()+1]\n",
    "    return crop\n",
    "    \n",
    "def symmetrize(img):\n",
    "    dim = max(img.shape)\n",
    "    emptySpace = [1]*dim\n",
    "    #less rows\n",
    "    if img.shape[0] < dim: \n",
    "        top = round((dim-img.shape[0])/2)\n",
    "        bot = dim-top-img.shape[0]\n",
    "        \n",
    "        newImg = np.vstack((np.array(top*[emptySpace]), img)) if top > 0 else img\n",
    "        newImg = np.vstack((newImg, np.array(bot*[emptySpace]))) if bot > 0 else newImg\n",
    "        return newImg\n",
    "    #less cols\n",
    "    else:  \n",
    "        left = round((dim-img.shape[1])/2)\n",
    "        right = dim-left-img.shape[1]\n",
    "        \n",
    "        newImg = np.hstack((np.transpose(np.array(left*[emptySpace])), img)) if left > 0 else img\n",
    "        newImg = np.hstack((newImg, np.transpose(np.array(right*[emptySpace]))))if right > 0 else newImg\n",
    "        return newImg\n",
    "    \n",
    "\n",
    "counts = [64, 63, 63, 63, 62, 62, 61, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63]    \n",
    "imgs = []\n",
    "cat = []\n",
    "i=0\n",
    "# NOTE: Change this variable to set correct location of letter data in your computer #\n",
    "PATH_TO_LETTERS='letters/'                                                           #\n",
    "######################################################################################\n",
    "for alph in string.ascii_uppercase:\n",
    "    for idx in range(1, counts[i]+1):\n",
    "        try:\n",
    "            img = plt.imread(f\"{PATH_TO_LETTERS}{alph}{idx}.png\")\n",
    "            img = denoise_tv_chambolle(img, weight=0.1, multichannel=True, n_iter_max=10)\n",
    "            img = rgb2gray(img)\n",
    "            thresh = threshold_otsu(img)\n",
    "            img = (img > thresh).astype(int)\n",
    "            img = removeSpace(img)\n",
    "            img = symmetrize(img)\n",
    "            img *= 255 # Change grayscale interval\n",
    "            img = gaussian(img, sigma=5, preserve_range=True).astype(int)\n",
    "            img = resize(img, (8, 8))\n",
    "            img = rescale_intensity(img, out_range=(0, 16))\n",
    "        \n",
    "            imgs.append((img, i, alph))\n",
    "            cat.append(i)\n",
    "        except ValueError as ve:\n",
    "            print(f\"Error processing picture {alph}{idx}.png, skipping...\")\n",
    "            continue\n",
    "    i += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.86% of letter images classified correctly\n",
      "Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.83      0.74        30\n",
      "           1       0.86      0.78      0.82        32\n",
      "           2       0.96      0.83      0.89        29\n",
      "           3       0.72      0.91      0.81        32\n",
      "           4       0.77      0.82      0.79        33\n",
      "           5       0.71      0.77      0.74        31\n",
      "           6       0.90      0.70      0.79        27\n",
      "           7       0.79      0.79      0.79        29\n",
      "           8       0.87      0.76      0.81        34\n",
      "           9       0.68      0.93      0.78        29\n",
      "          10       0.80      0.86      0.83        28\n",
      "          11       0.88      0.85      0.86        26\n",
      "          12       0.72      0.81      0.76        32\n",
      "          13       0.50      0.73      0.59        26\n",
      "          14       0.85      0.69      0.76        32\n",
      "          15       0.79      0.84      0.82        32\n",
      "          16       1.00      0.64      0.78        36\n",
      "          17       0.71      0.81      0.76        21\n",
      "          18       0.96      0.77      0.86        35\n",
      "          19       0.73      0.75      0.74        32\n",
      "          20       0.60      0.75      0.67        32\n",
      "          21       0.69      0.67      0.68        27\n",
      "          22       0.86      0.49      0.62        37\n",
      "          23       0.96      0.79      0.87        29\n",
      "          24       0.80      0.84      0.82        38\n",
      "          25       0.89      0.89      0.89        35\n",
      "\n",
      "    accuracy                           0.78       804\n",
      "   macro avg       0.79      0.78      0.78       804\n",
      "weighted avg       0.80      0.78      0.78       804\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[25  0  0  0  0  1  0  1  0  0  0  0  0  0  0  0  0  0  0  0  2  1  0  0\n",
      "   0  0]\n",
      " [ 2 25  0  0  2  0  0  0  0  1  0  0  0  0  0  1  0  0  0  0  0  0  1  0\n",
      "   0  0]\n",
      " [ 1  0 24  1  1  0  0  0  0  1  0  0  0  1  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 1  0  0 29  0  0  0  0  0  0  0  0  0  1  0  1  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0 27  3  0  0  1  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  1 24  0  1  0  0  0  0  1  0  0  0  0  0  0  4  0  0  0  0\n",
      "   0  0]\n",
      " [ 3  0  0  1  0  0 19  0  0  1  0  0  0  0  0  0  0  0  0  1  1  1  0  0\n",
      "   0  0]\n",
      " [ 1  0  0  0  1  0  0 23  0  1  0  1  1  0  0  0  0  0  0  0  0  0  0  0\n",
      "   1  0]\n",
      " [ 0  1  0  0  1  1  0  1 26  1  0  0  0  1  0  0  0  0  0  1  0  0  0  0\n",
      "   1  0]\n",
      " [ 0  0  0  0  0  0  0  0  1 27  0  0  0  0  0  0  0  0  0  0  1  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 24  0  0  1  0  0  0  2  0  0  0  1  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 22  0  0  0  0  0  0  0  1  3  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1 26  0  0  0  0  1  1  1  0  0  0  0\n",
      "   1  1]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  1  0  0 19  0  0  0  2  0  0  0  0  1  0\n",
      "   1  1]\n",
      " [ 0  2  0  5  0  1  0  0  0  1  0  0  0  0 22  1  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  0  0  1  1  0 27  0  0  0  0  1  0  0  0\n",
      "   1  0]\n",
      " [ 0  0  0  2  0  0  1  0  0  0  0  0  0  2  4  0 23  2  0  0  1  0  0  0\n",
      "   0  1]\n",
      " [ 0  0  0  0  1  0  0  0  0  1  0  0  1  0  0  1  0 17  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  1  0  2  0  0  1  1  0  0  1  1  0  0  0  0 27  0  1  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  1  0  0  1  1  0  2  0  0  0 24  1  0  0  0\n",
      "   1  0]\n",
      " [ 1  0  1  1  0  0  0  1  0  1  0  0  0  1  0  0  0  0  0  0 24  1  1  0\n",
      "   0  0]\n",
      " [ 3  0  0  0  0  0  0  0  0  2  3  0  0  0  0  0  0  0  0  0  1 18  0  0\n",
      "   0  0]\n",
      " [ 1  0  0  0  1  0  1  1  0  0  0  0  1  6  0  1  0  0  0  0  4  2 18  0\n",
      "   0  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  0  2  0  0  0  0  0  0  0  1  0 23\n",
      "   2  0]\n",
      " [ 0  1  0  0  0  0  0  0  1  0  0  0  1  0  0  0  0  0  0  1  0  1  0  1\n",
      "  32  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  1  0  1  1  0  0  0  0  0  0  0  0  0  0\n",
      "   0 31]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import svm, metrics\n",
    "import random\n",
    "\n",
    "# Shuffle letter data and select half of them as the training set\n",
    "random.shuffle(imgs)\n",
    "traindata = [img[0].flatten() for img in imgs[0:int(len(imgs)/2)]]\n",
    "labels = [img[1] for img in imgs[0:int(len(imgs)/2)]]\n",
    "# Train svm\n",
    "classifier = svm.SVC(gamma=0.001)\n",
    "classifier.fit(traindata, labels)\n",
    "# Select rest of the letter data as test set\n",
    "testdata = [img[0].flatten() for img in imgs[int(len(imgs)/2+1):]]\n",
    "corrLabel = np.array([img[1] for img in imgs[int(len(imgs)/2+1):]])\n",
    "# Let svm predict the labels\n",
    "predLabel = classifier.predict(testdata)\n",
    "\n",
    "# Calculate precentage how well svm succeeded\n",
    "prec = sum(predLabel == corrLabel) / len(testdata)\n",
    "\n",
    "# Some statistics how classification succeeded\n",
    "print(f'{round(prec*100, 2)}% of letter images classified correctly')\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(corrLabel, predLabel)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(corrLabel, predLabel))\n",
    "\n",
    "images_and_predictions = list(zip([img[0] for img in imgs[int(len(imgs)/2+1):]], predLabel))\n",
    "for index, (image, prediction) in enumerate(images_and_predictions[:4]):\n",
    "    plt.subplot(2, 4, index +5)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap='gray', interpolation='nearest')\n",
    "    plt.title(f'Pred: {string.ascii_uppercase[prediction]}')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
